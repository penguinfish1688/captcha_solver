{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bs = 128\n",
    "\n",
    "\n",
    "data = np.load(\"/mnt/c/Users/cck20/pytorch/data/dataset.npz\")\n",
    "x_train = data[\"x_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "x_valid = data[\"x_valid\"]\n",
    "y_valid = data[\"y_valid\"]\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbe520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make make the second index to RGB\n",
    "x_train = x_train.transpose(0, 3, 1, 2)\n",
    "x_valid = x_valid.transpose(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "x_valid = torch.tensor(x_valid, dtype=torch.float)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "train_loader = DataLoader(train_ds, bs, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 200\n",
    "from tqdm import tqdm\n",
    "class CNN_captcha_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2)\n",
    "        self.fc10 = nn.Linear(12672, 1000)\n",
    "        self.fc11 = nn.Linear(1000, 62)\n",
    "        self.fc20 = nn.Linear(12672, 1000)\n",
    "        self.fc21 = nn.Linear(1000, 62)\n",
    "        self.fc30 = nn.Linear(12672, 1000)\n",
    "        self.fc31 = nn.Linear(1000, 62)\n",
    "        self.fc40 = nn.Linear(12672, 1000)\n",
    "        self.fc41 = nn.Linear(1000, 62)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = self.conv1(xb)\n",
    "        xb = F.relu(xb)\n",
    "\n",
    "        xb = self.conv2(xb)\n",
    "        xb = F.relu(xb)\n",
    "        xb = F.max_pool2d(xb, kernel_size=2, stride=2)\n",
    "        xb = self.conv3(xb)\n",
    "        xb = F.relu(xb)\n",
    "        xb = F.max_pool2d(xb, kernel_size=2, stride=2)\n",
    "\n",
    "        xb = xb.flatten(start_dim=1)\n",
    "\n",
    "        xb = self.dropout1(xb)\n",
    "\n",
    "        xb1 = self.fc10(xb)\n",
    "        xb1 = F.relu(xb1)\n",
    "        xb1 = self.dropout2(xb1)\n",
    "        xb1 = self.fc11(xb1)\n",
    "\n",
    "        xb2 = self.fc20(xb)\n",
    "        xb2 = F.relu(xb2)\n",
    "        xb2 = self.dropout2(xb2)\n",
    "        xb2 = self.fc21(xb2)\n",
    "\n",
    "        xb3 = self.fc30(xb)\n",
    "        xb3 = F.relu(xb3)\n",
    "        xb3 = self.dropout2(xb3)\n",
    "        xb3 = self.fc31(xb3)\n",
    "\n",
    "        xb4 = self.fc40(xb)\n",
    "        xb4 = F.relu(xb4)\n",
    "        xb4 = self.dropout2(xb4)\n",
    "        xb4 = self.fc41(xb4)\n",
    "        return xb1, xb2, xb3, xb4\n",
    "    \n",
    "# pred 128*248 logits real 128*4 need to be one-hot encoded\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_loop(model):\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for xb, yb in train_loader:\n",
    "            count += 1\n",
    "            c1pred, c2pred, c3pred, c4pred = model(xb)\n",
    "\n",
    "            loss1 = loss_func(c1pred, yb[:,0])\n",
    "            loss2 = loss_func(c2pred, yb[:,1])\n",
    "            loss3 = loss_func(c3pred, yb[:,2])\n",
    "            loss4 = loss_func(c4pred, yb[:,3])\n",
    "            loss = (loss1+loss2+loss3+loss4)\n",
    "            loss.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            if count % 100 == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    loss_ave = 0\n",
    "                    loss1_ave = 0\n",
    "                    loss2_ave = 0\n",
    "                    loss3_ave = 0\n",
    "                    loss4_ave = 0\n",
    "                    size_v = 0\n",
    "                    for xv, yv in valid_loader:\n",
    "                        c1v, c2v, c3v, c4v = model(xv)\n",
    "\n",
    "                        vloss1 = loss_func(c1v, yv[:,0])\n",
    "                        vloss2 = loss_func(c2v, yv[:,1])\n",
    "                        vloss3 = loss_func(c3v, yv[:,2])\n",
    "                        vloss4 = loss_func(c4v, yv[:,3])\n",
    "                        vloss = (vloss1+vloss2+vloss3+vloss4)\n",
    "                        \n",
    "                        loss_ave += vloss.item()\n",
    "                        loss1_ave += vloss1.item()\n",
    "                        loss2_ave += vloss2.item()\n",
    "                        loss3_ave += vloss3.item()\n",
    "                        loss4_ave += vloss4.item()\n",
    "\n",
    "                        size_v += 1\n",
    "                    print(f\"{loss_ave/size_v}\")\n",
    "                model.train()\n",
    "\n",
    "\n",
    "model = CNN_captcha_model()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59824bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the picture and the prediction\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "def decode(char_pred: torch.Tensor):\n",
    "    char_table = string.digits + string.ascii_letters\n",
    "    max_idx = char_pred.argmax()\n",
    "    return char_table[max_idx]\n",
    "    \n",
    "\n",
    "for xv, yv in valid_loader:\n",
    "    c1v, c2v, c3v, c4v = model(xv)\n",
    "    for i in range(xv.shape[0]):\n",
    "        text = \"\"\n",
    "        text += decode(c1v[i])\n",
    "        text += decode(c2v[i])\n",
    "        text += decode(c3v[i])\n",
    "        text += decode(c4v[i])\n",
    "        print(text)\n",
    "        img = xv[i].transpose(0, 1)\n",
    "        img = img.transpose(1, 2)\n",
    "        img = img.clamp(0, 255).numpy().astype(\"uint8\")\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[[1], [2]],[[1], [2]],[[1], [2]]])\n",
    "print(y.shape)\n",
    "y = y.transpose(2, 0)\n",
    "print(y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
